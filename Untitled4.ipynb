{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMO6yy+fy0K2+GzFWvdVPfx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishwarya7774/aishwarya7774/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "0SsncGK9Ufuf",
        "outputId": "e3f2b593-8162-4fc2-da35-98ce47206f4a"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
        "from sklearn.cross_validation import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-16511e5259a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In2niDOGVOe2"
      },
      "source": [
        "class Data_Preprocessing:\n",
        "    emails= pd.DataFrame()\n",
        "    \n",
        "    def __init__(self):\n",
        "        print('Object created......Data Preprocessing starts')\n",
        "        print('----------------------------------------------------------------')\n",
        "    def read_data(self,input_dataset):\n",
        "        global emails\n",
        "        \n",
        "        print('Reading Data from the csv file')\n",
        "        emails= pd.read_csv(input_dataset, encoding='latin-1')\n",
        "        \n",
        "        print('Prints the first 5 rows of the dataframe')\n",
        "        print(emails.head())\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        print('Number of emails in each label')\n",
        "        print(emails.Label.value_counts())\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        print('A copy of the Email content is created')\n",
        "        text_feat= emails['Email'].copy()\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        print('Calling the text_process function to remove punctuation and stopwords.')\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('This might take few minutes')\n",
        "        text_feat= text_feat.apply(self.text_process)\n",
        "        print('\\n')\n",
        "        print(text_feat.head())\n",
        "        \n",
        "        return text_feat\n",
        "\n",
        "    def text_process(self, text):\n",
        "        #the text is translated by replacing empty string wth empty string and deleting all the characters found in string.punctuation\n",
        "        text= text.translate(str.maketrans('','',string.punctuation))\n",
        "        text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
        "        return \" \".join(text)\n",
        "    \n",
        "    def stemmer(self, text):\n",
        "        #stemming of content\n",
        "        text = text.split()\n",
        "        words = \"\"\n",
        "        for i in text:\n",
        "                stemmer = SnowballStemmer(\"english\")\n",
        "                words += (stemmer.stem(i))+\" \"\n",
        "        return words\n",
        "        \n",
        "    def feature_creation(self, text_feat):\n",
        "        print('Initialize the TfIdfVectorizer')\n",
        "        vectorizer= TfidfVectorizer('english')\n",
        "        features = vectorizer.fit_transform(text_feat)\n",
        "        print('***********Features created successfully*******************')\n",
        "        print('--------------------------------')\n",
        "        print('Features: ', features.shape)\n",
        "        print('\\n')\n",
        "        return features\n",
        "    \n",
        "    def featcreation_countvector(self, text_feat):\n",
        "        print('Initialize the count vector')\n",
        "        vector_count= CountVectorizer()\n",
        "        features_count= vector_count.fit_transform(text_feat)\n",
        "        print('Features using count vectorizer created successfully')\n",
        "        print('----------------------------------')\n",
        "        print('Features_count: ', features_count.shape)\n",
        "        print('\\n')\n",
        "        return features_count\n",
        "                \n",
        "    def split_train_test(self, features):\n",
        "        global emails\n",
        "        features_train, features_test, labels_train, labels_test = train_test_split(features, emails['Label'], test_size=0.3, random_state=111)\n",
        "        print('Features_train: ', features_train.shape)\n",
        "        print('Features_test: ', features_test.shape)\n",
        "        print('Labels_train: ', labels_train.shape)\n",
        "        print('Labels_test: ', labels_test.shape)\n",
        "        print('\\n')\n",
        "        return features_train, features_test, labels_train, labels_test"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgeOTfZtVOkG"
      },
      "source": [
        "class Parameter_tuning:\n",
        "    \n",
        "    def __init__(self, features_train, features_test, labels_train, labels_test):\n",
        "        print('Parameter tuning started')\n",
        "        print('----------------------------------------------------------------')\n",
        "        self.selecting_parameters(features_train, features_test, labels_train, labels_test)\n",
        "        \n",
        "    def selecting_parameters(self,features_train, features_test, labels_train, labels_test):\n",
        "        print('Parameter selection for each classifier started')\n",
        "        print('-----------------------------------------------')\n",
        "        print('This will take some time to determine the optimal parameters for each classifier.')\n",
        "        \n",
        "        #SVM Classifier\n",
        "        print('-----------Support Vector Machine-------------')\n",
        "        pred_scores_SVM = []\n",
        "        krnl = {'rbf' : 'rbf','polynominal' : 'poly', 'sigmoid': 'sigmoid'}\n",
        "        for k,v in krnl.items():\n",
        "            for i in np.linspace(0.05, 1, num=20):\n",
        "                svc = SVC(kernel=v, gamma=i)\n",
        "                svc.fit(features_train, labels_train)\n",
        "                pred = svc.predict(features_test)\n",
        "                pred_scores_SVM.append((k, [i, accuracy_score(labels_test,pred)]))\n",
        "        \n",
        "        #converts key-value pair to dataframe    \n",
        "        df = pd.DataFrame.from_items(pred_scores_SVM,orient='index', columns=['Gamma','Score'])\n",
        "        df['Score'].plot(kind='line', figsize=(11,6), ylim=(0.8,1.0))\n",
        "        \n",
        "        print(df[df['Score'] == df['Score'].max()])\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "        #K-Nearest Neighbour Classifier\n",
        "        print('---------------K-Nearest Neighbour-------------')\n",
        "        pred_scores_KNN = []\n",
        "        for i in range(3,61):\n",
        "            knc = KNeighborsClassifier(n_neighbors=i)\n",
        "            knc.fit(features_train, labels_train)\n",
        "            pred = knc.predict(features_test)\n",
        "            pred_scores_KNN.append((i, [accuracy_score(labels_test,pred)]))\n",
        "            \n",
        "        df = pd.DataFrame.from_items(pred_scores_KNN,orient='index', columns=['Score'])\n",
        "        df.plot(figsize=(11,6))\n",
        "        \n",
        "        print(df[df['Score'] == df['Score'].max()])\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "        #Multinomial Naive Bayes Classifier\n",
        "        print('-----------------Multinomial Naive Bayes-----------')\n",
        "        pred_scores_NB = []\n",
        "        for i in np.linspace(0.001, 0.1, num=20):\n",
        "            mnb = MultinomialNB(alpha=i)\n",
        "            mnb.fit(features_train, labels_train)\n",
        "            pred = mnb.predict(features_test)\n",
        "            pred_scores_NB.append((i, [accuracy_score(labels_test,pred)]))\n",
        "        df = pd.DataFrame.from_items(pred_scores_NB,orient='index', columns=['Score'])\n",
        "        df.plot(figsize=(11,6))\n",
        "        \n",
        "        print(df[df['Score'] == df['Score'].max()])\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "        #Decision Tree Classifier\n",
        "        print('------------------Decision Tree Classifier-------------------')\n",
        "        pred_scores_DT = []\n",
        "        for i in range(2,21):\n",
        "            dtc = DecisionTreeClassifier(min_samples_split=i, random_state=111)\n",
        "            dtc.fit(features_train, labels_train)\n",
        "            pred = dtc.predict(features_test)\n",
        "            pred_scores_DT.append((i, [accuracy_score(labels_test,pred)]))\n",
        "        df = pd.DataFrame.from_items(pred_scores_DT,orient='index', columns=['Score'])\n",
        "        df.plot(figsize=(11,6))\n",
        "        \n",
        "        print(df[df['Score'] == df['Score'].max()])\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "        #Logistic Regression\n",
        "        print('-------------Logistic Regression----------------')\n",
        "        slvr = {'newton-cg' : 'newton-cg', 'lbfgs': 'lbfgs'}\n",
        "        pred_scores_logistic = []\n",
        "        for k,v in slvr.items():\n",
        "            lrc = LogisticRegression(multi_class='multinomial', solver=v, class_weight = 'balanced')\n",
        "            lrc.fit(features_train, labels_train)\n",
        "            pred = lrc.predict(features_test)\n",
        "            pred_scores_logistic.append((k, [accuracy_score(labels_test,pred)]))\n",
        "        df = pd.DataFrame.from_items(pred_scores_logistic,orient='index', columns=['Score'])\n",
        "        df.plot(figsize=(11,6))\n",
        "        \n",
        "        print(df[df['Score'] == df['Score'].max()])\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "        #Ensemble Classifiers\n",
        "        print('Ensembles')\n",
        "        #Random Forest Classifier\n",
        "        print('------------Random Forest Classifier--------------')\n",
        "        pred_scores_RF = []\n",
        "        for i in range(2,36):\n",
        "            #n_estimators is the number of tress in the forest\n",
        "            rfc = RandomForestClassifier(n_estimators=i, random_state=111)\n",
        "            rfc.fit(features_train, labels_train)\n",
        "            pred = rfc.predict(features_test)\n",
        "            pred_scores_RF.append((i, [accuracy_score(labels_test,pred)]))\n",
        "        df = pd.DataFrame.from_items(pred_scores_RF,orient='index', columns=['Score'])\n",
        "        df.plot(figsize=(11,6))\n",
        "        \n",
        "        print(df[df['Score'] == df['Score'].max()])\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "        #AdaBoost Classifier\n",
        "        print('---------------AdaBoost Classifier-------------')\n",
        "        pred_scores_abc = []\n",
        "        for i in range(25,76):\n",
        "            #n_estimators: The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early.\n",
        "            abc = AdaBoostClassifier(n_estimators=i, random_state=111)\n",
        "            abc.fit(features_train, labels_train)\n",
        "            pred = abc.predict(features_test)\n",
        "            pred_scores_abc.append((i, [accuracy_score(labels_test,pred)]))\n",
        "        df = pd.DataFrame.from_items(pred_scores_abc,orient='index', columns=['Score'])\n",
        "        df.plot(figsize=(11,6))\n",
        "        \n",
        "        print(df[df['Score'] == df['Score'].max()])\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "        #Bagging Classifier\n",
        "        print('-----------Bagging Classifier-------------')\n",
        "        pred_scores_bc = []\n",
        "        for i in range(2,30):\n",
        "            #n_est: The number of base estimators in the ensemble.\n",
        "            bc = BaggingClassifier(n_estimators=i, random_state=111)\n",
        "            bc.fit(features_train, labels_train)\n",
        "            pred = bc.predict(features_test)\n",
        "            pred_scores_bc.append((i, [accuracy_score(labels_test,pred)]))\n",
        "        df = pd.DataFrame.from_items(pred_scores_bc,orient='index', columns=['Score'])\n",
        "        df.plot(figsize=(11,6))\n",
        "        \n",
        "        print(df[df['Score'] == df['Score'].max()])\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "        #ExtraTrees Classifier\n",
        "        print('------------ExtraTrees Classifier--------------')\n",
        "        pred_scores_etc = []\n",
        "        for i in range(2,30):\n",
        "            #n_estimators: The number of trees in the forest.\n",
        "            etc = ExtraTreesClassifier(n_estimators=i, random_state=111)\n",
        "            etc.fit(features_train, labels_train)\n",
        "            pred = etc.predict(features_test)\n",
        "            pred_scores_etc.append((i, [accuracy_score(labels_test,pred)]))\n",
        "        df = pd.DataFrame.from_items(pred_scores_etc,orient='index', columns=['Score'])\n",
        "        df.plot(figsize=(11,6))\n",
        "        \n",
        "        print(df[df['Score'] == df['Score'].max()])\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "        #SVM with Stochastic Gradient Descent Learning\n",
        "        print('SVM with Stochastic Gradient Descent Learning')\n",
        "        pred_scores_sgd_svm = []\n",
        "        for i in range(-6,1):\n",
        "            sgd_svm = SGDClassifier(loss=\"hinge\", penalty=\"l2\", alpha=10**i, random_state=111)\n",
        "            sgd_svm.fit(features_train, labels_train)\n",
        "            pred = sgd_svm.predict(features_test)\n",
        "            pred_scores_sgd_svm.append((i, [accuracy_score(labels_test,pred)]))\n",
        "        df = pd.DataFrame.from_items(pred_scores_sgd_svm,orient='index', columns=['Score'])\n",
        "        df.plot(figsize=(11,6))\n",
        "        \n",
        "        print(df[df['Score'] == df['Score'].max()])\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "        #LR with Stochastic Gradient Descent Learning\n",
        "        print('LR with Stochastic Gradient Descent Learning')\n",
        "        pred_scores_sgd_LR = []\n",
        "        for i in range(-6,1):\n",
        "            sgd_LR = SGDClassifier(loss=\"log\", penalty=\"l2\", alpha=10**i, random_state=111)\n",
        "            sgd_LR.fit(features_train, labels_train)\n",
        "            pred = sgd_LR.predict(features_test)\n",
        "            pred_scores_sgd_LR.append((i, [accuracy_score(labels_test,pred)]))\n",
        "        df = pd.DataFrame.from_items(pred_scores_sgd_LR,orient='index', columns=['Score'])\n",
        "        df.plot(figsize=(11,6))\n",
        "        \n",
        "        print(df[df['Score'] == df['Score'].max()])\n",
        "        print('************Parameter tunning finished successfully*************')\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIJ6HyG0VOxF"
      },
      "source": [
        "class Email_Classifictaion:\n",
        "    clfs={}\n",
        "    df= pd.DataFrame()\n",
        "    \n",
        "    def __init__(self):\n",
        "        print('---------Email Classifictaion starts------------')\n",
        "        print('-------------------------------------------------')\n",
        "        \n",
        "    def email_length(self):\n",
        "        global emails\n",
        "        print('Plotting histograms of length of the emails for each label')\n",
        "        print('----------------------------------------------------------------')\n",
        "        rcParams.update({'figure.autolayout': False})\n",
        "        plt.style.use('seaborn-bright')\n",
        "        emails.hist(column='Length', by='Label', bins=50, figsize=(11,5))\n",
        "        return\n",
        "\n",
        "    #Function created to fit the classifiers       \n",
        "    def train_classifier(self,clf, feature_train, labels_train):\n",
        "        clf.fit(feature_train, labels_train)\n",
        "        \n",
        "    #Function created to make predictions\n",
        "    def predict_labels(self,clf, features):\n",
        "        return (clf.predict(features))\n",
        "        \n",
        "    #Function created to create a classifiation report displaying Precision, Recall and F-score\n",
        "    def class_report(self,pred):\n",
        "        print(classification_report(labels_test,pred,labels=[\"FRAUD\",\"SPAM\",\"NORMAL\"],target_names=[\"FRAUD\",\"SPAM\",\"NORMAL\"]))\n",
        "    \n",
        "    #Function created to get a confusion matrix\n",
        "    def conf_matrix(self,pred):\n",
        "        global emails\n",
        "        label_feat=emails['Label'].copy()\n",
        "        label_feat= label_feat.unique()\n",
        "        conf_mat = confusion_matrix(labels_test, pred, labels=[\"FRAUD\",\"SPAM\",\"NORMAL\"])\n",
        "        fig, ax = plt.subplots(figsize=(5,5))\n",
        "        sns.heatmap(conf_mat, annot=True, fmt='d', xticklabels=label_feat, yticklabels=label_feat)\n",
        "        plt.ylabel('Actual')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.show()\n",
        "        \n",
        "    #Function to get various plots\n",
        "    def plot(self,df):\n",
        "        rcParams.update({'figure.autolayout': True})\n",
        "        df.plot(kind='bar', ylim=(0.85,1.0), figsize=(14,10), align='center', colormap=\"Accent\")\n",
        "        plt.xticks(np.arange(14), df.index)\n",
        "        plt.ylabel('Accuracy Score')\n",
        "        plt.title('Distribution by Classifier')\n",
        "        plt.grid(True)\n",
        "        plt.legend(bbox_to_anchor=(0.5, 1), loc=0, borderaxespad=0.)\n",
        "        \n",
        "    def classification(self, features_train, features_test, labels_train, labels_test):\n",
        "        global clfs, df\n",
        "        print('Initializing classifiers')\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        svc = SVC(kernel='sigmoid', gamma=1)\n",
        "        knc = KNeighborsClassifier(n_neighbors=5)\n",
        "        mnb = MultinomialNB(alpha=0.01)\n",
        "        dtc = DecisionTreeClassifier(min_samples_split=3, random_state=111)\n",
        "        lrc = LogisticRegression(multi_class='multinomial', solver='newton-cg', class_weight = 'balanced')\n",
        "        rfc = RandomForestClassifier(n_estimators=35, random_state=111)\n",
        "        abc = AdaBoostClassifier(n_estimators=25, random_state=111)\n",
        "        bc = BaggingClassifier(n_estimators=9, random_state=111)\n",
        "        etc = ExtraTreesClassifier(n_estimators=29, random_state=111)\n",
        "        \n",
        "        #Create a dictionary for the classifiers\n",
        "        clfs = {'SVC' : svc,'KN' : knc, 'NB': mnb, 'DT': dtc, 'LR': lrc, 'RF': rfc, 'AdaBoost': abc, 'BgC': bc, 'ETC': etc}\n",
        "        \n",
        "        print('Training various classifier models and making predictions')\n",
        "        pred_scores = []\n",
        "        for k,v in clfs.items():\n",
        "            self.train_classifier(v, features_train, labels_train)\n",
        "            pred = self.predict_labels(v,features_test)\n",
        "            pred_scores.append((k, [accuracy_score(labels_test,pred)]))\n",
        "            \n",
        "        df = pd.DataFrame.from_items(pred_scores,orient='index', columns=['Score'])\n",
        "        print('Accuracy Scores of classifiers')\n",
        "        print(df)\n",
        "        print('\\n')\n",
        "        \n",
        "        svc.fit(features_train, labels_train)\n",
        "        pred= svc.predict(features_test)\n",
        "        print('Classifictaion Report of SVC')\n",
        "        self.class_report(pred)\n",
        "        print('Get the confusion matrix')\n",
        "        self.conf_matrix(pred)\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "    def Stochastic_Gradient(self, features_train, features_test, labels_train, labels_test):\n",
        "        global df\n",
        "        \n",
        "        print('Building a SVM classifier with Stochastic Gradient Descent learning')\n",
        "        sgd_svm = SGDClassifier(loss=\"hinge\", penalty=\"l2\", alpha=1e-5, random_state=111)\n",
        "        sgd_svm.fit(features_train, labels_train)\n",
        "        pred1= sgd_svm.predict(features_test)\n",
        "        k1='SGD_SVM'\n",
        "        print('Accuracy_score: ',accuracy_score(labels_test,pred1))#0.98555\n",
        "        print('Classifictaion Report')\n",
        "        self.class_report(pred1)\n",
        "        print('Get the confusion matrix')\n",
        "        self.conf_matrix(pred1)\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        print('Building a Logistic Regression model with Stochastic Gradient Descent learning')\n",
        "        sgd_LR = SGDClassifier(loss=\"log\", penalty=\"l2\", alpha=1e-4, random_state=111)\n",
        "        sgd_LR.fit(features_train, labels_train)\n",
        "        pred2= sgd_LR.predict(features_test)\n",
        "        k2='SGD_LR'\n",
        "        print('Accuracy_score: ',accuracy_score(labels_test,pred2))#0.98222\n",
        "        print('Classifictaion Report')\n",
        "        self.class_report(pred2)\n",
        "        print('Get the confusion matrix')\n",
        "        self.conf_matrix(pred2)\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        pred_SGD=[]\n",
        "        pred_SGD.append((k1,[accuracy_score(labels_test,pred1)]))\n",
        "        pred_SGD.append((k2,[accuracy_score(labels_test,pred2)]))\n",
        "        df2 = pd.DataFrame.from_items(pred_SGD,orient='index', columns=['Score'])\n",
        "        df= df.append(df2)\n",
        "        print('Accuracy Scores')\n",
        "        print(df)\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "    def Vote(self, features_train, features_test, labels_train, labels_test):\n",
        "        global df\n",
        "        \n",
        "        print('Using Vote')\n",
        "        svc = SVC(kernel='sigmoid', gamma=1)\n",
        "        rfc = RandomForestClassifier(n_estimators=35, random_state=111)\n",
        "        abc = AdaBoostClassifier(n_estimators=25, random_state=111)\n",
        "        bc = BaggingClassifier(n_estimators=9, random_state=111)\n",
        "        etc = ExtraTreesClassifier(n_estimators=29, random_state=111)\n",
        "        \n",
        "        print('Vote on BGC, ETC, RF and AB with voting=\"soft\"')\n",
        "        eclf = VotingClassifier(estimators=[('BgC', bc), ('ETC', etc), ('RF', rfc),('AB',abc)], voting='soft')\n",
        "        eclf.fit(features_train,labels_train)\n",
        "        pred = eclf.predict(features_test)\n",
        "        k1= 'Vote(BC,ETC,RF,AB)'\n",
        "        print('Accuracy_score: ',accuracy_score(labels_test,pred))#0.975\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        print('Vote on BGC, ETC and RF with voting=\"hard\"')\n",
        "        eclf_2 = VotingClassifier(estimators=[('BgC', bc), ('ETC', etc), ('RF', rfc)], voting='hard')\n",
        "        eclf_2.fit(features_train,labels_train)\n",
        "        pred_2 = eclf_2.predict(features_test)\n",
        "        k2= 'Vote(BC,ETC,RF)'\n",
        "        print('Accuracy_score: ',accuracy_score(labels_test,pred_2))#0.982\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        print('Vote on BGC, RF and SVC with voting=\"hard\"')\n",
        "        eclf_3 = VotingClassifier(estimators=[('BgC', bc), ('RF', rfc),('SVC', svc)], voting='hard')\n",
        "        eclf_3.fit(features_train,labels_train)\n",
        "        pred_3= eclf_3.predict(features_test)\n",
        "        k3='Vote(SVC,BGC,RF)'\n",
        "        print('Accuracy_score: ',accuracy_score(labels_test,pred_3))#0.985\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        pred_vote=[]\n",
        "        pred_vote.append((k1, [accuracy_score(labels_test,pred)]))\n",
        "        pred_vote.append((k2, [accuracy_score(labels_test,pred_2)]))\n",
        "        pred_vote.append((k3, [accuracy_score(labels_test,pred_3)]))\n",
        "        \n",
        "        df3 = pd.DataFrame.from_items(pred_vote,orient='index', columns=['Score'])\n",
        "        df= df.append(df3)\n",
        "        print('Accuracy Scores')\n",
        "        print(df)\n",
        "        self.plot(df)\n",
        "        print('Classifictaion report of Vote(SVC,BGC,RF(hard))')\n",
        "        self.class_report(pred_3)\n",
        "        print('Get cofusion matrix of Vote(SVC,BGC,RF(hard))')\n",
        "        self.conf_matrix(pred_3)\n",
        "        print('Classifictaion completed successfully')\n",
        "        print('-------------------------------------')\n",
        "        print('\\n')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g05ia0ZHXTkX"
      },
      "source": [
        "class Email_Classification_Stemming:\n",
        "    df4= pd.DataFrame()\n",
        "    clfs_2={}\n",
        "    \n",
        "    def __init__(self):\n",
        "        print('---------Email Classifictaion with stemming starts------------')\n",
        "        print('-------------------------------------------------')\n",
        "        \n",
        "    def classification_stem(self, features_train, features_test, labels_train, labels_test):\n",
        "        global clfs_2, df4\n",
        "        email_class_obj= Email_Classifictaion()\n",
        "        \n",
        "        print('Initializing classifiers for stemming with different parameters')\n",
        "        print('----------------------------------------------------------------')\n",
        "        svc = SVC(kernel='sigmoid', gamma=0.7)\n",
        "        knc = KNeighborsClassifier(n_neighbors=5)\n",
        "        mnb = MultinomialNB(alpha=0.006)\n",
        "        dtc = DecisionTreeClassifier(min_samples_split=5, random_state=111)\n",
        "        lrc = LogisticRegression(multi_class='multinomial', solver='newton-cg', class_weight = 'balanced')\n",
        "        rfc = RandomForestClassifier(n_estimators=22, random_state=111)\n",
        "        abc = AdaBoostClassifier(n_estimators=65, random_state=111)\n",
        "        bc = BaggingClassifier(n_estimators=27, random_state=111)\n",
        "        etc = ExtraTreesClassifier(n_estimators=25, random_state=111)\n",
        "        \n",
        "        #Create a dictionary for the classifiers\n",
        "        clfs_2 = {'SVC' : svc,'KN' : knc, 'NB': mnb, 'DT': dtc, 'LR': lrc, 'RF': rfc, 'AdaBoost': abc, 'BgC': bc, 'ETC': etc}\n",
        "        \n",
        "        pred_scores = []\n",
        "        \n",
        "        for k,v in clfs_2.items():\n",
        "            email_class_obj.train_classifier(v, features_train, labels_train)\n",
        "            pred = email_class_obj.predict_labels(v,features_test)\n",
        "            pred_scores.append((k, [accuracy_score(labels_test,pred)]))\n",
        "            \n",
        "        df4 = pd.DataFrame.from_items(pred_scores,orient='index', columns=['Score2'])\n",
        "        print('Accuracy Scores of classifiers')\n",
        "        print(df4)\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "    def Stochastic_Gradient_stem(self, features_train, features_test, labels_train, labels_test):\n",
        "        global df4\n",
        "        \n",
        "        print('Building a SVM classifier with Stochastic Gradient Descent learning')\n",
        "        sgd_svm = SGDClassifier(loss=\"hinge\", penalty=\"l2\", alpha=1e-4, random_state=111)\n",
        "        sgd_svm.fit(features_train, labels_train)\n",
        "        pred1= sgd_svm.predict(features_test)\n",
        "        k1='SGD_SVM'\n",
        "        print('Accuracy_score: ',accuracy_score(labels_test,pred1))#0.98555\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        \n",
        "        print('Building a Logistic Regression model with Stochastic Gradient Descent learning')\n",
        "        sgd_LR = SGDClassifier(loss=\"log\", penalty=\"l2\", alpha=1e-4, random_state=111)\n",
        "        sgd_LR.fit(features_train, labels_train)\n",
        "        pred2= sgd_LR.predict(features_test)\n",
        "        k2='SGD_LR'\n",
        "        print('Accuracy_score: ',accuracy_score(labels_test,pred2))#0.98222\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        pred_SGD=[]\n",
        "        pred_SGD.append((k1,[accuracy_score(labels_test,pred1)]))\n",
        "        pred_SGD.append((k2,[accuracy_score(labels_test,pred2)]))\n",
        "        df5 = pd.DataFrame.from_items(pred_SGD,orient='index', columns=['Score2'])\n",
        "        df4= df4.append(df5)\n",
        "        print('Accuracy Scores')\n",
        "        print(df4)\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "    def Vote_Stem(self, features_train, features_test, labels_train, labels_test):\n",
        "        global df, df4\n",
        "        email_class_obj= Email_Classifictaion()\n",
        "        \n",
        "        print('Using Vote')\n",
        "        svc = SVC(kernel='sigmoid', gamma=0.7)\n",
        "        rfc = RandomForestClassifier(n_estimators=22, random_state=111)\n",
        "        abc = AdaBoostClassifier(n_estimators=65, random_state=111)\n",
        "        bc = BaggingClassifier(n_estimators=27, random_state=111)\n",
        "        etc = ExtraTreesClassifier(n_estimators=25, random_state=111)\n",
        "        \n",
        "        print('Vote on BGC, ETC, RF and AB with voting=\"soft\"')\n",
        "        eclf = VotingClassifier(estimators=[('BgC', bc), ('ETC', etc), ('RF', rfc),('AB',abc)], voting='soft')\n",
        "        eclf.fit(features_train,labels_train)\n",
        "        pred = eclf.predict(features_test)\n",
        "        k1= 'Vote(BC,ETC,RF,AB)'\n",
        "        print('Accuracy_score: ',accuracy_score(labels_test,pred))#0.975\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        print('Vote on BGC, ETC and RF with voting=\"hard\"')\n",
        "        eclf_2 = VotingClassifier(estimators=[('BgC', bc), ('ETC', etc), ('RF', rfc)], voting='hard')\n",
        "        eclf_2.fit(features_train,labels_train)\n",
        "        pred_2 = eclf_2.predict(features_test)\n",
        "        k2= 'Vote(BC,ETC,RF)'\n",
        "        print('Accuracy_score: ',accuracy_score(labels_test,pred_2))#0.982\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        print('Vote on BGC, RF and SVC with voting=\"hard\"')\n",
        "        eclf_3 = VotingClassifier(estimators=[('BgC', bc), ('RF', rfc),('SVC', svc)], voting='hard')\n",
        "        eclf_3.fit(features_train,labels_train)\n",
        "        pred_3= eclf_3.predict(features_test)\n",
        "        k3='Vote(SVC,BGC,RF)'\n",
        "        print('Accuracy_score: ',accuracy_score(labels_test,pred_3))#0.985\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        pred_vote=[]\n",
        "        pred_vote.append((k1, [accuracy_score(labels_test,pred)]))\n",
        "        pred_vote.append((k2, [accuracy_score(labels_test,pred_2)]))\n",
        "        pred_vote.append((k3, [accuracy_score(labels_test,pred_3)]))\n",
        "        \n",
        "        df6 = pd.DataFrame.from_items(pred_vote,orient='index', columns=['Score2'])\n",
        "        df4= df4.append(df6)\n",
        "        print(df4)\n",
        "        print('Accuracy Scores')\n",
        "        df = pd.concat([df,df4],axis=1)\n",
        "        print(df)\n",
        "        email_class_obj.plot(df)\n",
        "        print('Classifictaion completed successfully')\n",
        "        print('-------------------------------------')\n",
        "        print('\\n')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpVHiO2_XTsZ"
      },
      "source": [
        "class Length_Matrix:\n",
        "    df7= pd.DataFrame()\n",
        "    \n",
        "    def __init__(self):\n",
        "        print('Appending Length feature to the matrix')\n",
        "    \n",
        "    def Length_without_stemming(self, features):\n",
        "        global emails, clfs, df\n",
        "        Data_Preprocess_obj= Data_Preprocessing()\n",
        "        email_class_obj= Email_Classifictaion()\n",
        "        \n",
        "        print('Without Stemming')\n",
        "        lf = emails['Length'].as_matrix()\n",
        "        newfeat = np.hstack((features.todense(),lf[:, None]))\n",
        "        \n",
        "        print('Splitting features into train and test set')\n",
        "        features_train, features_test, labels_train, labels_test = Data_Preprocess_obj.split_train_test(newfeat)\n",
        "        \n",
        "        print('Training various classifiers')\n",
        "        pred_scores = []\n",
        "        for k,v in clfs.items():\n",
        "            email_class_obj.train_classifier(v, features_train, labels_train)\n",
        "            pred = email_class_obj.predict_labels(v,features_test)\n",
        "            pred_scores.append((k, [accuracy_score(labels_test,pred)]))\n",
        "            \n",
        "        df7 = pd.DataFrame.from_items(pred_scores,orient='index', columns=['Score3'])\n",
        "        print(df7)\n",
        "        \n",
        "        print('Building a SVM classifier with Stochastic Gradient Descent learning')\n",
        "        sgd_svm = SGDClassifier(loss=\"hinge\", penalty=\"l2\", alpha=1e-5, random_state=111)\n",
        "        sgd_svm.fit(features_train, labels_train)\n",
        "        pred1= sgd_svm.predict(features_test)\n",
        "        k1='SGD_SVM'\n",
        "        print('----------------------------------------------------------------')\n",
        "         \n",
        "        print('Building a Logistic Regression model with Stochastic Gradient Descent learning')\n",
        "        sgd_LR = SGDClassifier(loss=\"log\", penalty=\"l2\", alpha=1e-4, random_state=111)\n",
        "        sgd_LR.fit(features_train, labels_train)\n",
        "        pred2= sgd_LR.predict(features_test)\n",
        "        k2='SGD_LR'\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        pred_SGD=[]\n",
        "        pred_SGD.append((k1,[accuracy_score(labels_test,pred1)]))\n",
        "        pred_SGD.append((k2,[accuracy_score(labels_test,pred2)]))\n",
        "        df8 = pd.DataFrame.from_items(pred_SGD,orient='index', columns=['Score3'])\n",
        "        df7= df7.append(df8)\n",
        "        print('Accuracy Scores')\n",
        "        print(df7)\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        print('Using Vote')\n",
        "        svc = SVC(kernel='sigmoid', gamma=1)\n",
        "        rfc = RandomForestClassifier(n_estimators=35, random_state=111)\n",
        "        abc = AdaBoostClassifier(n_estimators=25, random_state=111)\n",
        "        bc = BaggingClassifier(n_estimators=9, random_state=111)\n",
        "        etc = ExtraTreesClassifier(n_estimators=29, random_state=111)\n",
        "        \n",
        "        print('Vote on BGC, ETC, RF and AB with voting=\"soft\"')\n",
        "        vote_l1 = VotingClassifier(estimators=[('BgC', bc), ('ETC', etc), ('RF', rfc), ('Ada', abc)], voting='soft')\n",
        "        vote_l1.fit(features_train,labels_train)\n",
        "        pred = vote_l1.predict(features_test)\n",
        "        k1= 'Vote(BC,ETC,RF,AB)'\n",
        "        \n",
        "        print('Vote on BGC, ETC and RF with voting=\"hard\"')\n",
        "        vote_l2 = VotingClassifier(estimators=[('BgC', bc), ('ETC', etc), ('RF', rfc)], voting='hard')\n",
        "        vote_l2.fit(features_train,labels_train)\n",
        "        pred_2 = vote_l2.predict(features_test)\n",
        "        k2= 'Vote(BC,ETC,RF)'\n",
        "        \n",
        "        print('Vote on BGC, RF and SVC with voting=\"hard\"')\n",
        "        vote_l3 = VotingClassifier(estimators=[('BgC', bc), ('RF', rfc),('SVC', svc)], voting='hard')\n",
        "        vote_l3.fit(features_train,labels_train)\n",
        "        pred_3 = vote_l3.predict(features_test)\n",
        "        k3='Vote(SVC,BGC,RF)'\n",
        "        \n",
        "        pred_vote_l1=[]\n",
        "        pred_vote_l1.append((k1, [accuracy_score(labels_test,pred)]))\n",
        "        pred_vote_l1.append((k2, [accuracy_score(labels_test,pred_2)]))\n",
        "        pred_vote_l1.append((k3, [accuracy_score(labels_test,pred_3)]))\n",
        "        \n",
        "        df9 = pd.DataFrame.from_items(pred_vote_l1,orient='index', columns=['Score3'])\n",
        "        df7= df7.append(df9)\n",
        "        print(df7)\n",
        "        df = pd.concat([df,df7],axis=1)\n",
        "        print('Accuracy Scores')\n",
        "        print(df)\n",
        "        print('\\n')\n",
        "        email_class_obj.plot(df)\n",
        "        \n",
        "    def Length_stemming(self, features_stem):\n",
        "        global emails, clfs_2, df\n",
        "        Data_Preprocess_obj= Data_Preprocessing()\n",
        "        email_class_obj= Email_Classifictaion()\n",
        "        \n",
        "        print('With Stemming')\n",
        "        lf = emails['Length'].as_matrix()\n",
        "        newfeat_stem = np.hstack((features_stem.todense(),lf[:, None]))\n",
        "        \n",
        "        print('Split the features into train and test set')\n",
        "        features_train, features_test, labels_train, labels_test = Data_Preprocess_obj.split_train_test(newfeat_stem)\n",
        "\n",
        "        print('Training various classifiers')\n",
        "        pred_scores = []\n",
        "        for k,v in clfs_2.items():\n",
        "            email_class_obj.train_classifier(v, features_train, labels_train)\n",
        "            pred = email_class_obj.predict_labels(v,features_test)\n",
        "            pred_scores.append((k, [accuracy_score(labels_test,pred)]))\n",
        "            \n",
        "        df10 = pd.DataFrame.from_items(pred_scores,orient='index', columns=['Score4'])\n",
        "        print(df10)\n",
        "        \n",
        "        print('Building a SVM classifier with Stochastic Gradient Descent learning')\n",
        "        sgd_svm = SGDClassifier(loss=\"hinge\", penalty=\"l2\", alpha=1e-4, random_state=111)\n",
        "        sgd_svm.fit(features_train, labels_train)\n",
        "        pred1= sgd_svm.predict(features_test)\n",
        "        k1='SGD_SVM'\n",
        "        print('----------------------------------------------------------------')\n",
        "         \n",
        "        print('Building a Logistic Regression model with Stochastic Gradient Descent learning')\n",
        "        sgd_LR = SGDClassifier(loss=\"log\", penalty=\"l2\", alpha=1e-4, random_state=111)\n",
        "        sgd_LR.fit(features_train, labels_train)\n",
        "        pred2= sgd_LR.predict(features_test)\n",
        "        k2='SGD_LR'\n",
        "        print('----------------------------------------------------------------')\n",
        "        \n",
        "        pred_SGD=[]\n",
        "        pred_SGD.append((k1,[accuracy_score(labels_test,pred1)]))\n",
        "        pred_SGD.append((k2,[accuracy_score(labels_test,pred2)]))\n",
        "        df11 = pd.DataFrame.from_items(pred_SGD,orient='index', columns=['Score4'])\n",
        "        df10= df10.append(df11)\n",
        "        print('Accuracy Scores')\n",
        "        print(df10)\n",
        "        print('----------------------------------------------------------------')\n",
        "        print('\\n')\n",
        "        \n",
        "        print('Using Vote')\n",
        "        svc = SVC(kernel='sigmoid', gamma=0.7)\n",
        "        rfc = RandomForestClassifier(n_estimators=22, random_state=111)\n",
        "        abc = AdaBoostClassifier(n_estimators=65, random_state=111)\n",
        "        bc = BaggingClassifier(n_estimators=27, random_state=111)\n",
        "        etc = ExtraTreesClassifier(n_estimators=25, random_state=111)\n",
        "        \n",
        "        print('Vote on BGC, ETC, RF and AB with voting=\"soft\"')\n",
        "        vote_l1 = VotingClassifier(estimators=[('BgC', bc), ('ETC', etc), ('RF', rfc), ('Ada', abc)], voting='soft')\n",
        "        vote_l1.fit(features_train,labels_train)\n",
        "        pred = vote_l1.predict(features_test)\n",
        "        k1= 'Vote(BC,ETC,RF,AB)'\n",
        "        \n",
        "        print('Vote on BGC, ETC and RF with voting=\"hard\"')\n",
        "        vote_l2 = VotingClassifier(estimators=[('BgC', bc), ('ETC', etc), ('RF', rfc)], voting='hard')\n",
        "        vote_l2.fit(features_train,labels_train)\n",
        "        pred_2 = vote_l2.predict(features_test)\n",
        "        k2= 'Vote(BC,ETC,RF)'\n",
        "        \n",
        "        print('Vote on BGC, RF and SVC with voting=\"hard\"')\n",
        "        vote_l3 = VotingClassifier(estimators=[('BgC', bc), ('RF', rfc),('SVC', svc)], voting='hard')\n",
        "        vote_l3.fit(features_train,labels_train)\n",
        "        pred_3 = vote_l3.predict(features_test)\n",
        "        k3='Vote(SVC,BGC,RF)'\n",
        "        \n",
        "        pred_vote_l2=[]\n",
        "        pred_vote_l2.append((k1, [accuracy_score(labels_test,pred)]))\n",
        "        pred_vote_l2.append((k2, [accuracy_score(labels_test,pred_2)]))\n",
        "        pred_vote_l2.append((k3, [accuracy_score(labels_test,pred_3)]))\n",
        "        \n",
        "        df12 = pd.DataFrame.from_items(pred_vote_l2,orient='index', columns=['Score4'])\n",
        "        df10= df10.append(df12)\n",
        "        print(df10)\n",
        "        df = pd.concat([df,df10],axis=1)\n",
        "        print('Accuracy Scores')\n",
        "        print(df)\n",
        "        print('\\n')\n",
        "        email_class_obj.plot(df)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "ufYQ7IlDX_cn",
        "outputId": "61dcda2c-4bf4-417a-fb1c-6e96d5515b80"
      },
      "source": [
        "'''***********************MAIN PROGRAM STARTS*******************************'''      \n",
        "\n",
        "input_dataset='F:\\WebMining\\SimarjotKaur_WM\\Code_WM\\Datasets/final_dataset.csv'\n",
        "\n",
        "#Creatig object of class Data_Preprocessing\n",
        "Processed_dataset= Data_Preprocessing()\n",
        "\n",
        "#Read data from the csv file, then removal of stopwords and punctuation\n",
        "text_feat=Processed_dataset.read_data(input_dataset)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object created......Data Preprocessing starts\n",
            "----------------------------------------------------------------\n",
            "Reading Data from the csv file\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-fd19121d1b96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#Read data from the csv file, then removal of stopwords and punctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtext_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mProcessed_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-67d046ff5f50>\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(self, input_dataset)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reading Data from the csv file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0memails\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prints the first 5 rows of the dataframe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:\\\\WebMining\\\\SimarjotKaur_WM\\\\Code_WM\\\\Datasets/final_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "fcCnnCCjX_fg",
        "outputId": "a47dfcfb-2ae2-4260-8d92-358f20f83dd2"
      },
      "source": [
        "'''************************************************************************\n",
        "*********************BLOCK-1: WITHOUT STEMMING*****************************\n",
        "***************************************************************************'''\n",
        "\n",
        "print('Calling the feature_creation function (TF-TDF)')\n",
        "print('----------------------------------------------------------------')\n",
        "features= Processed_dataset.feature_creation(text_feat)\n",
        "\n",
        "print('Splitting the features into train and test set')\n",
        "print('----------------------------------------------------------------')\n",
        "features_train, features_test, labels_train, labels_test= Processed_dataset.split_train_test(features)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calling the feature_creation function (TF-TDF)\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-52754c88f466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling the feature_creation function (TF-TDF)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mProcessed_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Splitting the features into train and test set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'text_feat' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ellFXWxsX_iJ"
      },
      "source": [
        "#Exceution of this function might take long as optimal parameters for each classifier are determined#\n",
        "#creating object of class Parameter_tuning.\n",
        "param_tuning=Parameter_tuning(features_train, features_test, labels_train, labels_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "uHux7_1oYX5B",
        "outputId": "3533e4e2-8155-4efa-f643-e627c3a5de50"
      },
      "source": [
        "#Exceution of this function might take long as optimal parameters for each classifier are determined#\n",
        "#creating object of class Parameter_tuning.\n",
        "param_tuning=Parameter_tuning(features_train, features_test, labels_train, labels_test)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5da6b402f0a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Exceution of this function might take long as optimal parameters for each classifier are determined#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#creating object of class Parameter_tuning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparam_tuning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParameter_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'features_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "RtBY6Rx5YX9C",
        "outputId": "502a9113-fe06-4053-9df4-7309aa1ad751"
      },
      "source": [
        "'''********************************************************************\n",
        "**************** BLOCK-2: WITH STEMMING *******************************\n",
        "********************************************************************'''\n",
        "print('Stemming of the content starts.....')\n",
        "text_feat_stem= text_feat.apply(Processed_dataset.stemmer)\n",
        "print('----------------------------------------------------------------')\n",
        "\n",
        "print('Calling the feature_creation function (TF-TDF)')\n",
        "features_stem= Processed_dataset.feature_creation(text_feat_stem)\n",
        "print('----------------------------------------------------------------')\n",
        "\n",
        "print('Splitting the features into train and test set')\n",
        "features_train_stem, features_test_stem, labels_train_stem, labels_test_stem= Processed_dataset.split_train_test(features_stem)\n",
        "print('----------------------------------------------------------------')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stemming of the content starts.....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-960043cbe59b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m ********************************************************************'''\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Stemming of the content starts.....'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtext_feat_stem\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtext_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProcessed_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'text_feat' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "yClSIgxeYYAr",
        "outputId": "393c7879-11ab-4691-a27c-83d4677348bd"
      },
      "source": [
        "#Exceution of this function might take long as optimal parameters for each classifier are determined#\n",
        "#creating object of class Parameter_tuning.\n",
        "param_tuning=Parameter_tuning(features_train_stem, features_test_stem, labels_train_stem, labels_test_stem)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-41167c74de2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Exceution of this function might take long as optimal parameters for each classifier are determined#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#creating object of class Parameter_tuning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparam_tuning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParameter_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_test_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test_stem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'features_train_stem' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "eox6-nfFYioA",
        "outputId": "92b3a0c1-3a72-4427-c792-d1ede17c258e"
      },
      "source": [
        "#Creating object for email classification with stemming\n",
        "email_class_stem= Email_Classification_Stemming()\n",
        "email_class_stem.classification_stem(features_train_stem, features_test_stem, labels_train_stem, labels_test_stem)\n",
        "email_class_stem.Stochastic_Gradient_stem(features_train_stem, features_test_stem, labels_train_stem, labels_test_stem)\n",
        "email_class_stem.Vote_Stem(features_train_stem, features_test_stem, labels_train_stem, labels_test_stem)\n",
        "\n",
        "'''**************************END BLOCK-2 **************************************'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------Email Classifictaion with stemming starts------------\n",
            "-------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-82f1c3f5e7f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Creating object for email classification with stemming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0memail_class_stem\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mEmail_Classification_Stemming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0memail_class_stem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_test_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test_stem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0memail_class_stem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStochastic_Gradient_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_test_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test_stem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0memail_class_stem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVote_Stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_test_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test_stem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'features_train_stem' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "07Gzuwm-Yiqv",
        "outputId": "70c5c8f0-7ff7-4b8f-9fe6-703ee5495734"
      },
      "source": [
        "'''********************************************************************************\n",
        "*****************************BLOCK-3: LENGTH MATRIX *******************************\n",
        "***********************************************************************************'''\n",
        "\n",
        "length_mat= Length_Matrix()\n",
        "length_mat.Length_without_stemming(features)\n",
        "length_mat.Length_stemming(features_stem)\n",
        "\n",
        "'''******************** END BLOCK-3 ***********************************************'''\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Appending Length feature to the matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-94e21c099d68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlength_mat\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLength_Matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlength_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLength_without_stemming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlength_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLength_stemming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_stem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "irOPKzeJYitm",
        "outputId": "be6e065b-98c2-4359-9c2d-195dd10dffcd"
      },
      "source": [
        "'''***********************************************************************************\n",
        "********************* BLOCK-4: COUNT VECTOR ******************************************\n",
        "***************************************************************************************'''\n",
        "\n",
        "print('Calling the function for feature cration using Count Vector')\n",
        "print('----------------------------------------------------------------')\n",
        "features_count= Processed_dataset.featcreation_countvector(text_feat)\n",
        "\n",
        "print('Splitting the features into train and test set')\n",
        "print('----------------------------------------------------------------')\n",
        "features_train_count, features_test_count, labels_train_count, labels_test_count= Processed_dataset.split_train_test(features_count)\n",
        "\n",
        "email_class.classification(features_train_count, features_test_count, labels_train_count, labels_test_count)\n",
        "email_class.Stochastic_Gradient(features_train_count, features_test_count, labels_train_count, labels_test_count)\n",
        "email_class.Vote(features_train_count, features_test_count, labels_train_count, labels_test_count)\n",
        "\n",
        "print('Calling the function for feature cration using Count Vector with stemming')\n",
        "features_count_stem= Processed_dataset.featcreation_countvector(text_feat_stem)\n",
        "print('----------------------------------------------------------------')\n",
        "\n",
        "print('Splitting the features into train and test set')\n",
        "features_train_count_stem, features_test_count_stem, labels_train_count_stem, labels_test_count_stem= Processed_dataset.split_train_test(features_count_stem)\n",
        "print('----------------------------------------------------------------')\n",
        "\n",
        "email_class_stem.classification_stem(features_train_count_stem, features_test_count_stem, labels_train_count_stem, labels_test_count_stem)\n",
        "email_class_stem.Stochastic_Gradient_stem(features_train_count_stem, features_test_count_stem, labels_train_count_stem, labels_test_count_stem)\n",
        "email_class_stem.Vote_Stem(features_train_count_stem, features_test_count_stem, labels_train_count_stem, labels_test_count_stem)\n",
        "\n",
        "'''*************************** END BLOCK-4 ***********************************************'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calling the function for feature cration using Count Vector\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e1b34e08e79b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling the function for feature cration using Count Vector'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfeatures_count\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mProcessed_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatcreation_countvector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Splitting the features into train and test set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'text_feat' is not defined"
          ]
        }
      ]
    }
  ]
}